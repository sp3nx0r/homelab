---
# Ansible playbook for Proxmox + Ollama + GPU passthrough setup
# Target: Miniforum MS-S1 MAX (Ryzen AI MAX+ 395 / Radeon 8060S)
#
# Usage:
#   ansible-playbook -i '192.168.5.5,' -u root proxmox-ollama-setup.yml
#
# Variables you may want to override:
#   -e ollama_api_key=<your-key>
#   -e ollama_models='["llama3.3","qwen2.5-coder:32b"]'

- name: Proxmox host configuration
  hosts: all
  gather_facts: true
  vars:
    # Network
    host_ip: 192.168.5.5
    gateway: 192.168.5.1
    bridge_port: enp97s0  # Primary Realtek NIC

    # Ollama LXC
    ollama_ctid: 100
    ollama_ip: 192.168.5.100
    ollama_disk_gb: 492
    ollama_cores: 16
    ollama_memory_mb: 98304
    ollama_api_key: "{{ lookup('env', 'OLLAMA_API_KEY') | default('CHANGE_ME_GENERATE_A_KEY', true) }}"
    ollama_models:
      - huihui_ai/qwen3-abliterated:latest
      - qwegabegoodhart/minimax-m2.1:latest
      - qwen3:32b
      - qwen3-coder:latest

    # OpenClaw LXC
    openclaw_ctid: 101
    openclaw_ip: 192.168.5.101
    openclaw_disk_gb: 16
    openclaw_cores: 4
    openclaw_memory_mb: 4096

    # SSH public key to install in containers
    ssh_pubkey_path: ~/.ssh/personal.pub

    # Realtek NIC PCI info (for recovery script)
    realtek_pci_id: "10ec:8127"
    realtek_bridge_addrs:
      - "0000:00:02.1"
      - "0000:00:02.2"

    # LXC template
    lxc_template: "debian-13-standard_13.1-2_amd64.tar.zst"
    lxc_template_url: "http://download.proxmox.com/images/system/{{ lxc_template }}"

  tasks:
    # =========================================================================
    # SECTION 1: APT - Switch to Proxmox community repos
    # =========================================================================
    - name: Disable PVE enterprise repo
      copy:
        dest: /etc/apt/sources.list.d/pve-enterprise.sources
        content: |
          Enabled: no
          Types: deb
          URIs: https://enterprise.proxmox.com/debian/pve
          Suites: trixie
          Components: pve-enterprise
          Signed-By: /usr/share/keyrings/proxmox-archive-keyring.gpg
        mode: "0644"

    - name: Disable Ceph enterprise repo
      copy:
        dest: /etc/apt/sources.list.d/ceph.sources
        content: |
          Enabled: no
          Types: deb
          URIs: https://enterprise.proxmox.com/debian/ceph-squid
          Suites: trixie
          Components: enterprise
          Signed-By: /usr/share/keyrings/proxmox-archive-keyring.gpg
        mode: "0644"

    - name: Add PVE no-subscription repo
      copy:
        dest: /etc/apt/sources.list.d/pve-no-subscription.sources
        content: |
          Types: deb
          URIs: http://download.proxmox.com/debian/pve
          Suites: trixie
          Components: pve-no-subscription
          Signed-By: /usr/share/keyrings/proxmox-archive-keyring.gpg
        mode: "0644"

    - name: Add Ceph no-subscription repo
      copy:
        dest: /etc/apt/sources.list.d/ceph-no-subscription.sources
        content: |
          Types: deb
          URIs: http://download.proxmox.com/debian/ceph-squid
          Suites: trixie
          Components: no-subscription
          Signed-By: /usr/share/keyrings/proxmox-archive-keyring.gpg
        mode: "0644"

    - name: Update apt cache
      apt:
        update_cache: true

    # =========================================================================
    # SECTION 2: GRUB - Disable ASPM for PCIe NICs
    # =========================================================================
    - name: Ensure GRUB defaults have pcie_aspm=off
      lineinfile:
        path: /etc/default/grub
        regexp: '^GRUB_CMDLINE_LINUX_DEFAULT='
        line: 'GRUB_CMDLINE_LINUX_DEFAULT="quiet pcie_aspm=off amdgpu.gttsize=98304 ttm.pages_limit=25165824"'
      register: grub_defaults

    - name: Update GRUB
      command: update-grub
      when: grub_installer.changed or grub_defaults.changed

    # =========================================================================
    # SECTION 3: /etc/hosts - Ensure hostname resolves
    # =========================================================================
    - name: Ensure hostname resolves in /etc/hosts
      lineinfile:
        path: /etc/hosts
        regexp: '.*{{ ansible_hostname }}.*'
        line: "{{ host_ip }} {{ ansible_hostname }}.securimancy.com {{ ansible_hostname }}"
        insertafter: '^127\.0\.0\.1'
        state: present

    # =========================================================================
    # SECTION 4: GPU - udev rules for container passthrough
    # =========================================================================
    - name: Create udev rules for GPU container access
      copy:
        dest: /etc/udev/rules.d/99-gpu-container.rules
        content: |
          SUBSYSTEM=="drm", MODE="0666"
          KERNEL=="kfd", MODE="0666"
        mode: "0644"
      register: udev_rules

    - name: Reload udev rules
      command: udevadm control --reload-rules
      when: udev_rules.changed

    # =========================================================================
    # SECTION 5: PCIe NIC recovery service
    # =========================================================================
    - name: Install PCIe NIC recovery script
      copy:
        dest: /usr/local/bin/pcie-nic-recovery.sh
        mode: "0755"
        content: |
          #!/bin/bash
          # PCIe NIC recovery - resets root port bridges if Realtek NICs are missing
          LOG_TAG="pcie-nic-recovery"

          if lspci -d {{ realtek_pci_id }} | grep -q Realtek; then
              logger -t $LOG_TAG "Realtek NICs detected, no recovery needed"
              exit 0
          fi

          logger -t $LOG_TAG "Realtek NICs NOT found, attempting PCIe bridge reset..."

          for BRIDGE in {{ realtek_bridge_addrs | join(' ') }}; do
              if [ -e /sys/bus/pci/devices/$BRIDGE ]; then
                  logger -t $LOG_TAG "Resetting bridge $BRIDGE"
                  echo 1 > /sys/bus/pci/devices/$BRIDGE/reset 2>/dev/null || \
                  setpci -s $BRIDGE BRIDGE_CONTROL.w=0x40:0x40 2>/dev/null
                  sleep 0.5
                  setpci -s $BRIDGE BRIDGE_CONTROL.w=0x00:0x40 2>/dev/null
                  sleep 0.5
              fi
          done

          sleep 1
          logger -t $LOG_TAG "Rescanning PCI bus..."
          echo 1 > /sys/bus/pci/rescan
          sleep 2

          if lspci -d {{ realtek_pci_id }} | grep -q Realtek; then
              logger -t $LOG_TAG "SUCCESS: Realtek NICs recovered after bridge reset"
              systemctl restart networking 2>/dev/null || true
          else
              logger -t $LOG_TAG "FAILED: Realtek NICs still not present after reset"
              for BRIDGE in {{ realtek_bridge_addrs | join(' ') }}; do
                  echo 1 > /sys/bus/pci/devices/$BRIDGE/remove 2>/dev/null
              done
              sleep 1
              echo 1 > /sys/bus/pci/rescan
              sleep 2
              if lspci -d {{ realtek_pci_id }} | grep -q Realtek; then
                  logger -t $LOG_TAG "SUCCESS: Realtek NICs recovered after bridge remove+rescan"
                  systemctl restart networking 2>/dev/null || true
              else
                  logger -t $LOG_TAG "FAILED: Realtek NICs could not be recovered. Full power cycle needed."
              fi
          fi

    - name: Install PCIe NIC recovery systemd service
      copy:
        dest: /etc/systemd/system/pcie-nic-recovery.service
        mode: "0644"
        content: |
          [Unit]
          Description=PCIe NIC recovery after dirty shutdown
          DefaultDependencies=no
          Before=network-pre.target systemd-networkd.service networking.service
          After=systemd-modules-load.service
          Wants=network-pre.target

          [Service]
          Type=oneshot
          ExecStart=/usr/local/bin/pcie-nic-recovery.sh
          RemainAfterExit=yes
          TimeoutStartSec=30

          [Install]
          WantedBy=sysinit.target
      register: nic_recovery_service

    - name: Enable PCIe NIC recovery service
      systemd:
        name: pcie-nic-recovery.service
        enabled: true
        daemon_reload: "{{ nic_recovery_service.changed }}"

    # =========================================================================
    # SECTION 6: Hardware watchdog via systemd
    # =========================================================================
    - name: Load SP5100 TCO watchdog module
      modprobe:
        name: sp5100_tco
        state: present

    - name: Ensure SP5100 TCO loads at boot
      copy:
        dest: /etc/modules-load.d/sp5100-tco.conf
        content: |
          sp5100_tco
        mode: "0644"

    - name: Configure systemd hardware watchdog
      copy:
        dest: /etc/systemd/system.conf.d/watchdog.conf
        content: |
          [Manager]
          RuntimeWatchdogSec=30
          RuntimeWatchdogPreSec=15
          RebootWatchdogSec=10min
          WatchdogDevice=/dev/watchdog1
        mode: "0644"

    # =========================================================================
    # SECTION 7a: Host memory tuning for LXC container cache pressure
    # =========================================================================
    # LXC containers share the host kernel page cache. Large model files
    # (Ollama) fill the cgroup's memory limit with cached pages. The kernel
    # won't reclaim them proactively, so Ollama sees "insufficient memory"
    # even though the cache is reclaimable. These sysctls + cgroup settings
    # fix that without resorting to global drop_caches.

    - name: Tune host sysctls for LXC memory cache management
      sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        sysctl_file: /etc/sysctl.d/99-lxc-memory.conf
        reload: true
        state: present
      loop:
        - name: vm.vfs_cache_pressure
          value: "200"
        - name: vm.min_free_kbytes
          value: "1048576"
        - name: vm.watermark_boost_factor
          value: "15000"
        - name: vm.watermark_scale_factor
          value: "50"

    - name: Install Ollama container memory reclaim service
      copy:
        dest: /etc/systemd/system/lxc-memory-reclaim@.service
        mode: "0644"
        content: |
          [Unit]
          Description=Reclaim cached memory for LXC container %i
          ConditionPathExists=/sys/fs/cgroup/lxc/%i/memory.reclaim

          [Service]
          Type=oneshot
          ExecStart=/bin/bash -c '\
            CGROUP=/sys/fs/cgroup/lxc/%i; \
            CURRENT=$(cat $CGROUP/memory.current 2>/dev/null || echo 0); \
            HIGH=$(cat $CGROUP/memory.high 2>/dev/null || echo 0); \
            if [ "$HIGH" = "max" ] || [ "$HIGH" -eq 0 ]; then exit 0; fi; \
            EXCESS=$((CURRENT - HIGH)); \
            if [ "$EXCESS" -gt 0 ]; then \
              echo $EXCESS > $CGROUP/memory.reclaim 2>/dev/null || true; \
              logger -t lxc-memory-reclaim "CT %i: reclaimed up to $((EXCESS/1048576))MiB"; \
            fi'

    - name: Install Ollama container memory reclaim timer
      copy:
        dest: /etc/systemd/system/lxc-memory-reclaim@.timer
        mode: "0644"
        content: |
          [Unit]
          Description=Periodic memory reclaim for LXC container %i

          [Timer]
          OnBootSec=5min
          OnUnitActiveSec=10min
          RandomizedDelaySec=60
          AccuracySec=60

          [Install]
          WantedBy=timers.target
      register: reclaim_timer

    - name: Enable memory reclaim timer for Ollama container
      systemd:
        name: "lxc-memory-reclaim@{{ ollama_ctid }}.timer"
        enabled: true
        state: started
        daemon_reload: "{{ reclaim_timer.changed }}"

    # =========================================================================
    # SECTION 7b: LXC template
    # =========================================================================
    - name: Download LXC template
      command: pveam download local {{ lxc_template }}
      args:
        creates: /var/lib/vz/template/cache/{{ lxc_template }}

    # =========================================================================
    # SECTION 8: Ollama LXC container (CT 100)
    # =========================================================================
    - name: Check if Ollama container exists
      command: pct status {{ ollama_ctid }}
      register: ollama_ct_check
      ignore_errors: true
      changed_when: false

    - name: Create Ollama container
      command: >
        pct create {{ ollama_ctid }}
        local:vztmpl/{{ lxc_template }}
        --hostname ollama
        --cores {{ ollama_cores }}
        --memory {{ ollama_memory_mb }}
        --swap 0
        --storage local-lvm
        --rootfs local-lvm:{{ ollama_disk_gb }}
        --net0 name=eth0,bridge=vmbr0,ip={{ ollama_ip }}/24,gw={{ gateway }}
        --unprivileged 1
        --features nesting=1
        --onboot 1
        --startup order=1
      when: ollama_ct_check.rc != 0

    - name: Configure GPU passthrough for Ollama container
      blockinfile:
        path: /etc/pve/lxc/{{ ollama_ctid }}.conf
        marker: "# {mark} GPU PASSTHROUGH"
        block: |
          lxc.cgroup2.devices.allow: c 226:* rwm
          lxc.cgroup2.devices.allow: c 234:* rwm
          lxc.mount.entry: /dev/dri dev/dri none bind,optional,create=dir 0 0
          lxc.mount.entry: /dev/kfd dev/kfd none bind,optional,create=file 0 0

    - name: Start Ollama container
      command: pct start {{ ollama_ctid }}
      register: ollama_start
      failed_when: ollama_start.rc != 0 and 'already running' not in ollama_start.stderr
      changed_when: ollama_start.rc == 0

    - name: Wait for Ollama container to be ready
      pause:
        seconds: 5

    - name: Apply cgroup memory.high for Ollama container (90% of hard limit)
      shell: |
        CGROUP="/sys/fs/cgroup/lxc/{{ ollama_ctid }}"
        if [ -f "$CGROUP/memory.high" ]; then
          HIGH=$(( {{ ollama_memory_mb }} * 1024 * 1024 * 9 / 10 ))
          echo $HIGH > "$CGROUP/memory.high"
          echo "Set memory.high to $((HIGH/1048576))MiB"
        else
          echo "cgroup path not found or memory.high not available"
        fi
      register: memory_high_result
      changed_when: "'Set memory.high' in memory_high_result.stdout"

    - name: Ensure Proxmox snippets directory exists
      file:
        path: /var/lib/vz/snippets
        state: directory
        mode: "0755"

    - name: Install hookscript as Proxmox snippet
      copy:
        dest: /var/lib/vz/snippets/hookscript-memory-high-{{ ollama_ctid }}.sh
        mode: "0755"
        content: |
          #!/usr/bin/perl
          # Proxmox hookscript: set memory.high to 90% of memory.max
          use strict;
          use warnings;

          my $vmid = shift;
          my $phase = shift;

          if ($phase eq 'post-start') {
              sleep(2);
              my $cgroup = "/sys/fs/cgroup/lxc/$vmid";
              if (-f "$cgroup/memory.high") {
                  open(my $fh, '<', "$cgroup/memory.max") or exit 0;
                  my $max = <$fh>;
                  chomp($max);
                  close($fh);
                  if ($max ne 'max' && $max > 0) {
                      my $high = int($max * 9 / 10);
                      open(my $wh, '>', "$cgroup/memory.high") or exit 0;
                      print $wh $high;
                      close($wh);
                      system("logger -t hookscript 'CT $vmid: set memory.high to " . int($high/1048576) . "MiB'");
                  }
              }
          }

          exit(0);

    - name: Set hookscript on Ollama container
      command: pct set {{ ollama_ctid }} --hookscript local:snippets/hookscript-memory-high-{{ ollama_ctid }}.sh
      register: hookscript_set
      changed_when: hookscript_set.rc == 0
      failed_when: false

    - name: Set DNS in Ollama container
      command: pct exec {{ ollama_ctid }} -- bash -c 'echo "nameserver 192.168.5.1" > /etc/resolv.conf'

    - name: Fix locale in Ollama container - uncomment en_US.UTF-8
      command: pct exec {{ ollama_ctid }} -- sed -i 's/^# *\(en_US\.UTF-8 UTF-8\)/\1/' /etc/locale.gen

    - name: Generate locale in Ollama container
      command: pct exec {{ ollama_ctid }} -- locale-gen

    - name: Install Ollama prerequisites
      command: pct exec {{ ollama_ctid }} -- bash -c 'apt-get update -qq && apt-get install -y -qq curl zstd nginx pciutils vmtouch'
      register: ollama_prereqs
      changed_when: "'newly installed' in ollama_prereqs.stdout"

    - name: Check if Ollama is installed
      command: pct exec {{ ollama_ctid }} -- which ollama
      register: ollama_installed
      ignore_errors: true
      changed_when: false

    - name: Install Ollama
      command: pct exec {{ ollama_ctid }} -- bash -c 'curl -fsSL https://ollama.com/install.sh | sh'
      when: ollama_installed.rc != 0
      timeout: 300

    - name: Configure Ollama daemon overrides
      command: >
        pct exec {{ ollama_ctid }} -- bash -c '
        mkdir -p /etc/systemd/system/ollama.service.d &&
        cat > /etc/systemd/system/ollama.service.d/override.conf <<EOF
        [Service]
        Environment="OLLAMA_HOST=0.0.0.0:11434"
        Environment="OLLAMA_KEEP_ALIVE=24h"
        Environment="OLLAMA_NUM_PARALLEL=1"
        Environment="OLLAMA_CONTEXT_LENGTH=65536"
        Environment="OLLAMA_LOAD_TIMEOUT=30m"
        Environment="HSA_ENABLE_SDMA=0"
        EOF'

    # TODO: actually use this
    - name: Configure nginx API key proxy for Ollama
      command: >
        pct exec {{ ollama_ctid }} -- bash -c '
        cat > /etc/nginx/sites-available/ollama <<NGINX
        server {
            listen {{ ollama_ip }}:11435;

            location / {
                if (\$http_authorization != "Bearer {{ ollama_api_key }}") {
                    return 401 "{\"error\": \"unauthorized\"}";
                }

                proxy_pass http://127.0.0.1:11434;
                proxy_set_header Host \$host;
                proxy_set_header X-Real-IP \$remote_addr;
                proxy_buffering off;
                proxy_read_timeout 600s;
                proxy_send_timeout 600s;

                proxy_set_header Connection "";
                proxy_http_version 1.1;
                chunked_transfer_encoding on;
            }
        }
        NGINX
        ln -sf /etc/nginx/sites-available/ollama /etc/nginx/sites-enabled/ollama &&
        rm -f /etc/nginx/sites-enabled/default'

    - name: Ensure nginx waits for network to be online before starting
      command: >
        pct exec {{ ollama_ctid }} -- bash -c '
        systemctl enable systemd-networkd-wait-online.service'

    - name: Install Ollama model pre-warm service
      command: >
        pct exec {{ ollama_ctid }} -- bash -c '
        cat > /etc/systemd/system/ollama-warm-cache.service <<WARMEOF
        [Unit]
        Description=Pre-warm Ollama model files into page cache
        Before=ollama.service
        After=local-fs.target

        [Service]
        Type=oneshot
        ExecStart=/usr/bin/vmtouch -t /usr/share/ollama/.ollama/models/blobs/
        TimeoutStartSec=300
        Nice=19

        [Install]
        WantedBy=multi-user.target
        WARMEOF'

    - name: Restart Ollama and nginx in container
      command: >
        pct exec {{ ollama_ctid }} -- bash -c '
        systemctl daemon-reload &&
        systemctl enable ollama-warm-cache.service &&
        systemctl restart ollama &&
        systemctl restart nginx &&
        systemctl enable nginx'

    - name: Wait for Ollama to be ready
      command: pct exec {{ ollama_ctid }} -- curl -sf --max-time 5 http://localhost:11434/
      register: ollama_health
      retries: 10
      delay: 3
      until: ollama_health.rc == 0

    - name: Install SSH key in Ollama container
      command: >
        pct exec {{ ollama_ctid }} -- bash -c '
        mkdir -p /root/.ssh &&
        chmod 700 /root/.ssh &&
        echo "{{ lookup("file", ssh_pubkey_path) }}" > /root/.ssh/authorized_keys &&
        chmod 600 /root/.ssh/authorized_keys'

    - name: Pull Ollama models
      command: pct exec {{ ollama_ctid }} -- ollama pull {{ item }}
      loop: "{{ ollama_models }}"
      timeout: 900
      register: model_pull
      changed_when: "'already exists' not in model_pull.stdout"

    # =========================================================================
    # SECTION 9: OpenClaw LXC container (CT 101)
    # =========================================================================
    - name: Check if OpenClaw container exists
      command: pct status {{ openclaw_ctid }}
      register: openclaw_ct_check
      ignore_errors: true
      changed_when: false

    - name: Create OpenClaw container
      command: >
        pct create {{ openclaw_ctid }}
        local:vztmpl/{{ lxc_template }}
        --hostname openclaw
        --cores {{ openclaw_cores }}
        --memory {{ openclaw_memory_mb }}
        --swap 0
        --storage local-lvm
        --rootfs local-lvm:{{ openclaw_disk_gb }}
        --net0 name=eth0,bridge=vmbr0,ip={{ openclaw_ip }}/24,gw={{ gateway }},firewall=1
        --unprivileged 1
        --features nesting=1
        --onboot 1
        --startup order=2
      when: openclaw_ct_check.rc != 0

    - name: Start OpenClaw container
      command: pct start {{ openclaw_ctid }}
      register: openclaw_start
      failed_when: openclaw_start.rc != 0 and 'already running' not in openclaw_start.stderr
      changed_when: openclaw_start.rc == 0

    - name: Wait for OpenClaw container to be ready
      pause:
        seconds: 5

    - name: Set DNS in OpenClaw container
      command: pct exec {{ openclaw_ctid }} -- bash -c 'echo "nameserver 1.1.1.1" > /etc/resolv.conf'

    - name: Fix locale in OpenClaw container - uncomment en_US.UTF-8
      command: pct exec {{ openclaw_ctid }} -- sed -i 's/^# *\(en_US\.UTF-8 UTF-8\)/\1/' /etc/locale.gen

    - name: Generate locale in OpenClaw container
      command: pct exec {{ openclaw_ctid }} -- locale-gen

    - name: Install curl in OpenClaw container
      command: pct exec {{ openclaw_ctid }} -- bash -c 'apt-get update -qq && apt-get install -y -qq curl'
      register: openclaw_prereqs
      changed_when: "'newly installed' in openclaw_prereqs.stdout"

    - name: Install SSH key in OpenClaw container
      command: >
        pct exec {{ openclaw_ctid }} -- bash -c '
        mkdir -p /root/.ssh &&
        chmod 700 /root/.ssh &&
        echo "{{ lookup("file", ssh_pubkey_path) }}" > /root/.ssh/authorized_keys &&
        chmod 600 /root/.ssh/authorized_keys'

    # =========================================================================
    # SECTION 10: OpenClaw backup (git repo on host, rsync from CT 101)
    # =========================================================================
    # Syncs ~/.openclaw from the OpenClaw container to a git repo on the
    # Proxmox host every 30 minutes. Each sync auto-commits if files changed.
    # The repo can later be pushed to GitHub for offsite backup.

    - name: Install git and git-lfs on Proxmox host
      apt:
        name:
          - git
          - git-lfs
        state: present

    - name: Initialize OpenClaw backup repo
      shell: |
        mkdir -p /root/backups/openclaw
        cd /root/backups/openclaw
        if [ ! -d .git ]; then
          git init
          git lfs install
          git lfs track "*.db" "*.sqlite" "*.sqlite3" "*.bin" "*.tar" "*.tar.gz" "*.zip"
          git add .gitattributes
          git -c user.name="backup" -c user.email="backup@proxmox.local" \
            commit -m "Initialize backup repo with LFS tracking"
        fi
      args:
        creates: /root/backups/openclaw/.git

    - name: Install .gitignore for OpenClaw backup
      copy:
        dest: /root/backups/openclaw/.gitignore
        mode: "0644"
        content: |
          # OpenClaw backup .gitignore
          # Temp and lock files
          *.tmp
          *.lock
          *.swp
          *~

          # Logs rotate frequently and aren't worth versioning
          logs/

    - name: Install OpenClaw backup sync script
      copy:
        dest: /usr/local/bin/openclaw-backup.sh
        mode: "0755"
        content: |
          #!/bin/bash
          # Sync ~/.openclaw from CT {{ openclaw_ctid }} to local git repo
          set -euo pipefail
          LOG_TAG="openclaw-backup"
          BACKUP_DIR="/root/backups/openclaw"
          SSH_KEY="{{ ssh_pubkey_path | replace('.pub', '') }}"
          SOURCE="root@{{ openclaw_ip }}:~/.openclaw/"

          # Skip if container is not running
          if ! pct status {{ openclaw_ctid }} 2>/dev/null | grep -q running; then
            logger -t "$LOG_TAG" "CT {{ openclaw_ctid }} not running, skipping"
            exit 0
          fi

          # Rsync from container to backup dir
          rsync -az --delete \
            --exclude='.git/' \
            --exclude='*.tmp' \
            --exclude='*.lock' \
            --exclude='*.swp' \
            --exclude='logs/' \
            -e "ssh -i $SSH_KEY -o StrictHostKeyChecking=no -o ConnectTimeout=10" \
            "$SOURCE" "$BACKUP_DIR/"

          cd "$BACKUP_DIR"

          # Check for changes
          git add -A
          if git diff --cached --quiet; then
            logger -t "$LOG_TAG" "No changes detected"
            exit 0
          fi

          # Build commit message from changed files
          ADDED=$(git diff --cached --numstat | grep -c '^[0-9]' || true)
          SUMMARY=$(git diff --cached --stat | tail -1)
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")

          git -c user.name="backup" -c user.email="backup@proxmox.local" \
            commit -m "backup: $TIMESTAMP" -m "$SUMMARY"

          logger -t "$LOG_TAG" "Committed: $SUMMARY"

    - name: Install OpenClaw backup systemd service
      copy:
        dest: /etc/systemd/system/openclaw-backup.service
        mode: "0644"
        content: |
          [Unit]
          Description=Sync OpenClaw data to local git backup
          After=network-online.target
          Wants=network-online.target

          [Service]
          Type=oneshot
          ExecStart=/usr/local/bin/openclaw-backup.sh
          TimeoutStartSec=120
          Nice=19
          IOSchedulingClass=idle

    - name: Install OpenClaw backup systemd timer
      copy:
        dest: /etc/systemd/system/openclaw-backup.timer
        mode: "0644"
        content: |
          [Unit]
          Description=Periodic OpenClaw backup sync

          [Timer]
          OnBootSec=10min
          OnUnitActiveSec=30min
          RandomizedDelaySec=120
          AccuracySec=60
          Persistent=true

          [Install]
          WantedBy=timers.target
      register: openclaw_backup_timer

    - name: Enable OpenClaw backup timer
      systemd:
        name: openclaw-backup.timer
        enabled: true
        state: started
        daemon_reload: "{{ openclaw_backup_timer.changed }}"

    - name: Run initial OpenClaw backup
      command: /usr/local/bin/openclaw-backup.sh
      register: initial_backup
      changed_when: initial_backup.rc == 0

    # =========================================================================
    # SECTION 11: Firewall - restrict OpenClaw container outbound access
    # =========================================================================
    # OpenClaw (CT 101) is untrusted. It should only reach:
    #   - Ollama API (192.168.5.100:11435)
    #   - DNS (port 53, required for internet)
    #   - The public internet
    # All other LAN/private network access is blocked. Inbound is restricted
    # to SSH from the Proxmox host (for rsync backups).
    #
    # Uses Proxmox's built-in firewall (pve-firewall), which handles the
    # bridge/FORWARD chain complexity for LXC containers automatically.

    - name: Enable Proxmox datacenter firewall with permissive defaults
      copy:
        dest: /etc/pve/firewall/cluster.fw
        mode: "0640"
        content: |
          [OPTIONS]
          enable: 1
          policy_in: ACCEPT
          policy_out: ACCEPT

          [IPSET lan_rfc1918]
          10.0.0.0/8
          172.16.0.0/12
          192.168.0.0/16

    - name: Install OpenClaw container firewall rules
      copy:
        dest: /etc/pve/firewall/{{ openclaw_ctid }}.fw
        mode: "0640"
        content: |
          [OPTIONS]
          enable: 1
          policy_in: DROP
          policy_out: DROP
          log_level_in: nolog
          log_level_out: nolog

          [RULES]
          # --- Outbound ---
          # Allow Ollama API
          OUT ACCEPT -dest {{ ollama_ip }} -p tcp -dport 11435

          # Allow DNS (required for internet hostname resolution)
          OUT ACCEPT -p udp -dport 53
          OUT ACCEPT -p tcp -dport 53

          # Block all private/LAN networks (first-match, so above rules take priority)
          OUT DROP -dest 10.0.0.0/8 -log nolog
          OUT DROP -dest 172.16.0.0/12 -log nolog
          OUT DROP -dest 192.168.0.0/16 -log nolog

          # Block link-local and metadata
          OUT DROP -dest 169.254.0.0/16 -log nolog

          # Allow everything else (public internet)
          OUT ACCEPT

          # --- Inbound ---
          # Allow SSH from Proxmox host (rsync backups) and trusted network
          IN ACCEPT -source {{ host_ip }} -p tcp -dport 22
          IN ACCEPT -source 192.168.0.0/24 -p tcp -dport 22

          # Allow ICMP from LAN (ping for diagnostics)
          IN ACCEPT -source 192.168.5.0/24 -p icmp

    - name: Restart pve-firewall to apply rules
      systemd:
        name: pve-firewall
        state: restarted

    # =========================================================================
    # SECTION 12: Validation
    # =========================================================================
    - name: Verify Ollama API with key from OpenClaw
      command: >
        pct exec {{ openclaw_ctid }} -- curl -sf --max-time 5
        -H "Authorization: Bearer {{ ollama_api_key }}"
        http://{{ ollama_ip }}:11435/
      register: api_test
      changed_when: false

    - name: Print summary
      debug:
        msg: |
          ============================================
          Setup complete!
          ============================================
          Proxmox host:     {{ host_ip }}
          Ollama container:  CT {{ ollama_ctid }} @ {{ ollama_ip }}
            - API (auth):    http://{{ ollama_ip }}:11435
            - API (local):   http://127.0.0.1:11434  (inside container)
            - API key:       {{ ollama_api_key }}
            - Models:        {{ ollama_models | join(', ') }}
            - GPU:           AMD Radeon 8060S via ROCm (63.7 GiB)
          OpenClaw container: CT {{ openclaw_ctid }} @ {{ openclaw_ip }}

          SSH access:
            ssh -i {{ ssh_pubkey_path | replace('.pub','') }} root@{{ ollama_ip }}
            ssh -i {{ ssh_pubkey_path | replace('.pub','') }} root@{{ openclaw_ip }}

          OpenClaw backup:     /root/backups/openclaw (every 30min)
          OpenClaw firewall:   outbound restricted (Ollama + DNS + internet only)
          PCIe NIC recovery:   enabled (auto-resets on boot)
          Hardware watchdog:    SP5100 TCO (30s timeout)
          ============================================
